{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc9a5be-bfe5-40ab-82a5-e5ba1aaca56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sridharv2010\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading transformers-4.51.1-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 3.7/10.4 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.4 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 23.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 23.1 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.30.2 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.1\n"
     ]
    }
   ],
   "source": [
    "# Install the Hugging Face Transformers library\n",
    "!pip install transformers\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9675c087-305f-4641-a601-d25cfb126e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e166a3ea1c46278cab16fad8e9e0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridharv2010\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sridharv2010\\.cache\\huggingface\\hub\\models--yiyanghkust--finbert-tone. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae6c37ff3db4f4e815b8c0281c254eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c756131761c4d378751f5bd95cde071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f63bcd4e1c4ae289cd9442c90d2714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline stock        date  \\\n",
      "0  AI Daily: Analyst sees Apple  Alibaba partners...  aapl  2025-03-03   \n",
      "1  Apple’s iPhone 16e Is Likely to Underwhelm  Sa...  aapl  2025-03-03   \n",
      "2  Apple CEO teases ‘something in the Air’ this week  aapl  2025-03-03   \n",
      "3  Apple’s iPhone ceded market share in China  Eu...  aapl  2025-03-03   \n",
      "4  Apple (AAPL): New Buy Recommendation for This ...  aapl  2025-03-03   \n",
      "\n",
      "     open   close sentiment_label  sentiment_score  \n",
      "0  241.79  238.03        Positive         1.000000  \n",
      "1  241.79  238.03         Neutral         0.735460  \n",
      "2  241.79  238.03         Neutral         0.999914  \n",
      "3  241.79  238.03         Neutral         0.997822  \n",
      "4  241.79  238.03        Positive         1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the FinBERT model and tokenizer from Hugging Face\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# Create a sentiment analysis pipeline\n",
    "finbert_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('aggregate.csv')\n",
    "\n",
    "headlines = data['headline'].tolist()\n",
    "\n",
    "# Perform sentiment analysis on the headlines\n",
    "results = finbert_pipeline(headlines)\n",
    "\n",
    "# Add sentiment results to the dataset\n",
    "data['sentiment_label'] = [result['label'] for result in results]\n",
    "data['sentiment_score'] = [result['score'] for result in results]\n",
    "\n",
    "#Sentiment labels (LABEL_0, LABEL_1, LABEL_2) are mapped to their corresponding sentiments (neutral, positive, negative).\n",
    "#The sentiment_score column represents the confidence level of the model for its prediction. \n",
    "#They are probabilities ranging from 0 to 1. A higher score indicates greater confidence in the assigned label. For example:\n",
    "#LABEL_1 with a score of 0.95 means the model is 95% confident that the sentiment is positive.\n",
    "#LABEL_2 with a score of 0.85 means the model is 85% confident that the sentiment is negative.\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "data.to_csv('sentiment_scored_headlines_FinBERT.csv', index=False)\n",
    "\n",
    "# Display sample results\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Erdos Institute)",
   "language": "python",
   "name": "erdos_spring_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
